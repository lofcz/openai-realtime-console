{"version":3,"file":"audio-lib.min.js","sources":["../lib/wav_packer.js","../lib/analysis/constants.js","../lib/analysis/audio_analysis.js","../lib/worklets/stream_processor.js","../lib/wav_stream_player.js","../lib/worklets/audio_processor.js","../lib/wav_recorder.js"],"sourcesContent":["/**\n * Raw wav audio file contents\n * @typedef {Object} WavPackerAudioType\n * @property {Blob} blob\n * @property {string} url\n * @property {number} channelCount\n * @property {number} sampleRate\n * @property {number} duration\n */\n\n/**\n * Utility class for assembling PCM16 \"audio/wav\" data\n * @class\n */\nexport class WavPacker {\n  /**\n   * Converts Float32Array of amplitude data to ArrayBuffer in Int16Array format\n   * @param {Float32Array} float32Array\n   * @returns {ArrayBuffer}\n   */\n  static floatTo16BitPCM(float32Array) {\n    const buffer = new ArrayBuffer(float32Array.length * 2);\n    const view = new DataView(buffer);\n    let offset = 0;\n    for (let i = 0; i < float32Array.length; i++, offset += 2) {\n      let s = Math.max(-1, Math.min(1, float32Array[i]));\n      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n    return buffer;\n  }\n\n  /**\n   * Concatenates two ArrayBuffers\n   * @param {ArrayBuffer} leftBuffer\n   * @param {ArrayBuffer} rightBuffer\n   * @returns {ArrayBuffer}\n   */\n  static mergeBuffers(leftBuffer, rightBuffer) {\n    const tmpArray = new Uint8Array(\n      leftBuffer.byteLength + rightBuffer.byteLength\n    );\n    tmpArray.set(new Uint8Array(leftBuffer), 0);\n    tmpArray.set(new Uint8Array(rightBuffer), leftBuffer.byteLength);\n    return tmpArray.buffer;\n  }\n\n  /**\n   * Packs data into an Int16 format\n   * @private\n   * @param {number} size 0 = 1x Int16, 1 = 2x Int16\n   * @param {number} arg value to pack\n   * @returns\n   */\n  _packData(size, arg) {\n    return [\n      new Uint8Array([arg, arg >> 8]),\n      new Uint8Array([arg, arg >> 8, arg >> 16, arg >> 24]),\n    ][size];\n  }\n\n  /**\n   * Packs audio into \"audio/wav\" Blob\n   * @param {number} sampleRate\n   * @param {{bitsPerSample: number, channels: Array<Float32Array>, data: Int16Array}} audio\n   * @returns {WavPackerAudioType}\n   */\n  pack(sampleRate, audio) {\n    if (!audio?.bitsPerSample) {\n      throw new Error(`Missing \"bitsPerSample\"`);\n    } else if (!audio?.channels) {\n      throw new Error(`Missing \"channels\"`);\n    } else if (!audio?.data) {\n      throw new Error(`Missing \"data\"`);\n    }\n    const { bitsPerSample, channels, data } = audio;\n    const output = [\n      // Header\n      'RIFF',\n      this._packData(\n        1,\n        4 + (8 + 24) /* chunk 1 length */ + (8 + 8) /* chunk 2 length */\n      ), // Length\n      'WAVE',\n      // chunk 1\n      'fmt ', // Sub-chunk identifier\n      this._packData(1, 16), // Chunk length\n      this._packData(0, 1), // Audio format (1 is linear quantization)\n      this._packData(0, channels.length),\n      this._packData(1, sampleRate),\n      this._packData(1, (sampleRate * channels.length * bitsPerSample) / 8), // Byte rate\n      this._packData(0, (channels.length * bitsPerSample) / 8),\n      this._packData(0, bitsPerSample),\n      // chunk 2\n      'data', // Sub-chunk identifier\n      this._packData(\n        1,\n        (channels[0].length * channels.length * bitsPerSample) / 8\n      ), // Chunk length\n      data,\n    ];\n    const blob = new Blob(output, { type: 'audio/mpeg' });\n    const url = URL.createObjectURL(blob);\n    return {\n      blob,\n      url,\n      channelCount: channels.length,\n      sampleRate,\n      duration: data.byteLength / (channels.length * sampleRate * 2),\n    };\n  }\n}\n\nglobalThis.WavPacker = WavPacker;\n","/**\n * Constants for help with visualization\n * Helps map frequency ranges from Fast Fourier Transform\n * to human-interpretable ranges, notably music ranges and\n * human vocal ranges.\n */\n\n// Eighth octave frequencies\nconst octave8Frequencies = [\n  4186.01, 4434.92, 4698.63, 4978.03, 5274.04, 5587.65, 5919.91, 6271.93,\n  6644.88, 7040.0, 7458.62, 7902.13,\n];\n\n// Labels for each of the above frequencies\nconst octave8FrequencyLabels = [\n  'C',\n  'C#',\n  'D',\n  'D#',\n  'E',\n  'F',\n  'F#',\n  'G',\n  'G#',\n  'A',\n  'A#',\n  'B',\n];\n\n/**\n * All note frequencies from 1st to 8th octave\n * in format \"A#8\" (A#, 8th octave)\n */\nexport const noteFrequencies = [];\nexport const noteFrequencyLabels = [];\nfor (let i = 1; i <= 8; i++) {\n  for (let f = 0; f < octave8Frequencies.length; f++) {\n    const freq = octave8Frequencies[f];\n    noteFrequencies.push(freq / Math.pow(2, 8 - i));\n    noteFrequencyLabels.push(octave8FrequencyLabels[f] + i);\n  }\n}\n\n/**\n * Subset of the note frequencies between 32 and 2000 Hz\n * 6 octave range: C1 to B6\n */\nconst voiceFrequencyRange = [32.0, 2000.0];\nexport const voiceFrequencies = noteFrequencies.filter((_, i) => {\n  return (\n    noteFrequencies[i] > voiceFrequencyRange[0] &&\n    noteFrequencies[i] < voiceFrequencyRange[1]\n  );\n});\nexport const voiceFrequencyLabels = noteFrequencyLabels.filter((_, i) => {\n  return (\n    noteFrequencies[i] > voiceFrequencyRange[0] &&\n    noteFrequencies[i] < voiceFrequencyRange[1]\n  );\n});\n","import {\n  noteFrequencies,\n  noteFrequencyLabels,\n  voiceFrequencies,\n  voiceFrequencyLabels,\n} from './constants.js';\n\n/**\n * Output of AudioAnalysis for the frequency domain of the audio\n * @typedef {Object} AudioAnalysisOutputType\n * @property {Float32Array} values Amplitude of this frequency between {0, 1} inclusive\n * @property {number[]} frequencies Raw frequency bucket values\n * @property {string[]} labels Labels for the frequency bucket values\n */\n\n/**\n * Analyzes audio for visual output\n * @class\n */\nexport class AudioAnalysis {\n  /**\n   * Retrieves frequency domain data from an AnalyserNode adjusted to a decibel range\n   * returns human-readable formatting and labels\n   * @param {AnalyserNode} analyser\n   * @param {number} sampleRate\n   * @param {Float32Array} [fftResult]\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\n   * @param {number} [minDecibels] default -100\n   * @param {number} [maxDecibels] default -30\n   * @returns {AudioAnalysisOutputType}\n   */\n  static getFrequencies(\n    analyser,\n    sampleRate,\n    fftResult,\n    analysisType = 'frequency',\n    minDecibels = -100,\n    maxDecibels = -30,\n  ) {\n    if (!fftResult) {\n      fftResult = new Float32Array(analyser.frequencyBinCount);\n      analyser.getFloatFrequencyData(fftResult);\n    }\n    const nyquistFrequency = sampleRate / 2;\n    const frequencyStep = (1 / fftResult.length) * nyquistFrequency;\n    let outputValues;\n    let frequencies;\n    let labels;\n    if (analysisType === 'music' || analysisType === 'voice') {\n      const useFrequencies =\n        analysisType === 'voice' ? voiceFrequencies : noteFrequencies;\n      const aggregateOutput = Array(useFrequencies.length).fill(minDecibels);\n      for (let i = 0; i < fftResult.length; i++) {\n        const frequency = i * frequencyStep;\n        const amplitude = fftResult[i];\n        for (let n = useFrequencies.length - 1; n >= 0; n--) {\n          if (frequency > useFrequencies[n]) {\n            aggregateOutput[n] = Math.max(aggregateOutput[n], amplitude);\n            break;\n          }\n        }\n      }\n      outputValues = aggregateOutput;\n      frequencies =\n        analysisType === 'voice' ? voiceFrequencies : noteFrequencies;\n      labels =\n        analysisType === 'voice' ? voiceFrequencyLabels : noteFrequencyLabels;\n    } else {\n      outputValues = Array.from(fftResult);\n      frequencies = outputValues.map((_, i) => frequencyStep * i);\n      labels = frequencies.map((f) => `${f.toFixed(2)} Hz`);\n    }\n    // We normalize to {0, 1}\n    const normalizedOutput = outputValues.map((v) => {\n      return Math.max(\n        0,\n        Math.min((v - minDecibels) / (maxDecibels - minDecibels), 1),\n      );\n    });\n    const values = new Float32Array(normalizedOutput);\n    return {\n      values,\n      frequencies,\n      labels,\n    };\n  }\n\n  /**\n   * Creates a new AudioAnalysis instance for an HTMLAudioElement\n   * @param {HTMLAudioElement} audioElement\n   * @param {AudioBuffer|null} [audioBuffer] If provided, will cache all frequency domain data from the buffer\n   * @returns {AudioAnalysis}\n   */\n  constructor(audioElement, audioBuffer = null) {\n    this.fftResults = [];\n    if (audioBuffer) {\n      /**\n       * Modified from\n       * https://stackoverflow.com/questions/75063715/using-the-web-audio-api-to-analyze-a-song-without-playing\n       *\n       * We do this to populate FFT values for the audio if provided an `audioBuffer`\n       * The reason to do this is that Safari fails when using `createMediaElementSource`\n       * This has a non-zero RAM cost so we only opt-in to run it on Safari, Chrome is better\n       */\n      const { length, sampleRate } = audioBuffer;\n      const offlineAudioContext = new OfflineAudioContext({\n        length,\n        sampleRate,\n      });\n      const source = offlineAudioContext.createBufferSource();\n      source.buffer = audioBuffer;\n      const analyser = offlineAudioContext.createAnalyser();\n      analyser.fftSize = 8192;\n      analyser.smoothingTimeConstant = 0.1;\n      source.connect(analyser);\n      // limit is :: 128 / sampleRate;\n      // but we just want 60fps - cuts ~1s from 6MB to 1MB of RAM\n      const renderQuantumInSeconds = 1 / 60;\n      const durationInSeconds = length / sampleRate;\n      const analyze = (index) => {\n        const suspendTime = renderQuantumInSeconds * index;\n        if (suspendTime < durationInSeconds) {\n          offlineAudioContext.suspend(suspendTime).then(() => {\n            const fftResult = new Float32Array(analyser.frequencyBinCount);\n            analyser.getFloatFrequencyData(fftResult);\n            this.fftResults.push(fftResult);\n            analyze(index + 1);\n          });\n        }\n        if (index === 1) {\n          offlineAudioContext.startRendering();\n        } else {\n          offlineAudioContext.resume();\n        }\n      };\n      source.start(0);\n      analyze(1);\n      this.audio = audioElement;\n      this.context = offlineAudioContext;\n      this.analyser = analyser;\n      this.sampleRate = sampleRate;\n      this.audioBuffer = audioBuffer;\n    } else {\n      const audioContext = new AudioContext();\n      const track = audioContext.createMediaElementSource(audioElement);\n      const analyser = audioContext.createAnalyser();\n      analyser.fftSize = 8192;\n      analyser.smoothingTimeConstant = 0.1;\n      track.connect(analyser);\n      analyser.connect(audioContext.destination);\n      this.audio = audioElement;\n      this.context = audioContext;\n      this.analyser = analyser;\n      this.sampleRate = this.context.sampleRate;\n      this.audioBuffer = null;\n    }\n  }\n\n  /**\n   * Gets the current frequency domain data from the playing audio track\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\n   * @param {number} [minDecibels] default -100\n   * @param {number} [maxDecibels] default -30\n   * @returns {AudioAnalysisOutputType}\n   */\n  getFrequencies(\n    analysisType = 'frequency',\n    minDecibels = -100,\n    maxDecibels = -30,\n  ) {\n    let fftResult = null;\n    if (this.audioBuffer && this.fftResults.length) {\n      const pct = this.audio.currentTime / this.audio.duration;\n      const index = Math.min(\n        (pct * this.fftResults.length) | 0,\n        this.fftResults.length - 1,\n      );\n      fftResult = this.fftResults[index];\n    }\n    return AudioAnalysis.getFrequencies(\n      this.analyser,\n      this.sampleRate,\n      fftResult,\n      analysisType,\n      minDecibels,\n      maxDecibels,\n    );\n  }\n\n  /**\n   * Resume the internal AudioContext if it was suspended due to the lack of\n   * user interaction when the AudioAnalysis was instantiated.\n   * @returns {Promise<true>}\n   */\n  async resumeIfSuspended() {\n    if (this.context.state === 'suspended') {\n      await this.context.resume();\n    }\n    return true;\n  }\n}\n\nglobalThis.AudioAnalysis = AudioAnalysis;\n","export const StreamProcessorWorklet = `\nclass StreamProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.hasStarted = false;\n    this.hasInterrupted = false;\n    this.outputBuffers = [];\n    this.bufferLength = 128;\n    this.write = { buffer: new Float32Array(this.bufferLength), trackId: null };\n    this.writeOffset = 0;\n    this.trackSampleOffsets = {};\n    this.port.onmessage = (event) => {\n      if (event.data) {\n        const payload = event.data;\n        if (payload.event === 'write') {\n          const int16Array = payload.buffer;\n          const float32Array = new Float32Array(int16Array.length);\n          for (let i = 0; i < int16Array.length; i++) {\n            float32Array[i] = int16Array[i] / 0x8000; // Convert Int16 to Float32\n          }\n          this.writeData(float32Array, payload.trackId);\n        } else if (\n          payload.event === 'offset' ||\n          payload.event === 'interrupt'\n        ) {\n          const requestId = payload.requestId;\n          const trackId = this.write.trackId;\n          const offset = this.trackSampleOffsets[trackId] || 0;\n          this.port.postMessage({\n            event: 'offset',\n            requestId,\n            trackId,\n            offset,\n          });\n          if (payload.event === 'interrupt') {\n            this.hasInterrupted = true;\n          }\n        } else {\n          throw new Error(\\`Unhandled event \"\\${payload.event}\"\\`);\n        }\n      }\n    };\n  }\n\n  writeData(float32Array, trackId = null) {\n    let { buffer } = this.write;\n    let offset = this.writeOffset;\n    for (let i = 0; i < float32Array.length; i++) {\n      buffer[offset++] = float32Array[i];\n      if (offset >= buffer.length) {\n        this.outputBuffers.push(this.write);\n        this.write = { buffer: new Float32Array(this.bufferLength), trackId };\n        buffer = this.write.buffer;\n        offset = 0;\n      }\n    }\n    this.writeOffset = offset;\n    return true;\n  }\n\n  process(inputs, outputs, parameters) {\n    const output = outputs[0];\n    const outputChannelData = output[0];\n    const outputBuffers = this.outputBuffers;\n    if (this.hasInterrupted) {\n      this.port.postMessage({ event: 'stop' });\n      return false;\n    } else if (outputBuffers.length) {\n      this.hasStarted = true;\n      const { buffer, trackId } = outputBuffers.shift();\n      for (let i = 0; i < outputChannelData.length; i++) {\n        outputChannelData[i] = buffer[i] || 0;\n      }\n      if (trackId) {\n        this.trackSampleOffsets[trackId] =\n          this.trackSampleOffsets[trackId] || 0;\n        this.trackSampleOffsets[trackId] += buffer.length;\n      }\n      return true;\n    } else if (this.hasStarted) {\n      this.port.postMessage({ event: 'stop' });\n      return false;\n    } else {\n      return true;\n    }\n  }\n}\n\nregisterProcessor('stream_processor', StreamProcessor);\n`;\n\nconst script = new Blob([StreamProcessorWorklet], {\n  type: 'application/javascript',\n});\nconst src = URL.createObjectURL(script);\nexport const StreamProcessorSrc = src;\n","import { StreamProcessorSrc } from './worklets/stream_processor.js';\nimport { AudioAnalysis } from './analysis/audio_analysis.js';\n\n/**\n * Plays audio streams received in raw PCM16 chunks from the browser\n * @class\n */\nexport class WavStreamPlayer {\n  /**\n   * Creates a new WavStreamPlayer instance\n   * @param {{sampleRate?: number}} options\n   * @returns {WavStreamPlayer}\n   */\n  constructor({ sampleRate = 44100 } = {}) {\n    this.scriptSrc = StreamProcessorSrc;\n    this.sampleRate = sampleRate;\n    this.context = null;\n    this.stream = null;\n    this.analyser = null;\n    this.trackSampleOffsets = {};\n    this.interruptedTrackIds = {};\n  }\n\n  /**\n   * Connects the audio context and enables output to speakers\n   * @returns {Promise<true>}\n   */\n  async connect() {\n    this.context = new AudioContext({ sampleRate: this.sampleRate });\n    if (this.context.state === 'suspended') {\n      await this.context.resume();\n    }\n    try {\n      await this.context.audioWorklet.addModule(this.scriptSrc);\n    } catch (e) {\n      console.error(e);\n      throw new Error(`Could not add audioWorklet module: ${this.scriptSrc}`);\n    }\n    const analyser = this.context.createAnalyser();\n    analyser.fftSize = 8192;\n    analyser.smoothingTimeConstant = 0.1;\n    this.analyser = analyser;\n    return true;\n  }\n\n  /**\n   * Gets the current frequency domain data from the playing track\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\n   * @param {number} [minDecibels] default -100\n   * @param {number} [maxDecibels] default -30\n   * @returns {import('./analysis/audio_analysis.js').AudioAnalysisOutputType}\n   */\n  getFrequencies(\n    analysisType = 'frequency',\n    minDecibels = -100,\n    maxDecibels = -30\n  ) {\n    if (!this.analyser) {\n      throw new Error('Not connected, please call .connect() first');\n    }\n    return AudioAnalysis.getFrequencies(\n      this.analyser,\n      this.sampleRate,\n      null,\n      analysisType,\n      minDecibels,\n      maxDecibels\n    );\n  }\n\n  /**\n   * Starts audio streaming\n   * @private\n   * @returns {Promise<true>}\n   */\n  _start() {\n    const streamNode = new AudioWorkletNode(this.context, 'stream_processor');\n    streamNode.connect(this.context.destination);\n    streamNode.port.onmessage = (e) => {\n      const { event } = e.data;\n      if (event === 'stop') {\n        streamNode.disconnect();\n        this.stream = null;\n      } else if (event === 'offset') {\n        const { requestId, trackId, offset } = e.data;\n        const currentTime = offset / this.sampleRate;\n        this.trackSampleOffsets[requestId] = { trackId, offset, currentTime };\n      }\n    };\n    this.analyser.disconnect();\n    streamNode.connect(this.analyser);\n    this.stream = streamNode;\n    return true;\n  }\n\n  /**\n   * Adds 16BitPCM data to the currently playing audio stream\n   * You can add chunks beyond the current play point and they will be queued for play\n   * @param {ArrayBuffer|Int16Array} arrayBuffer\n   * @param {string} [trackId]\n   * @returns {Int16Array}\n   */\n  add16BitPCM(arrayBuffer, trackId = 'default') {\n    if (typeof trackId !== 'string') {\n      throw new Error(`trackId must be a string`);\n    } else if (this.interruptedTrackIds[trackId]) {\n      return;\n    }\n    if (!this.stream) {\n      this._start();\n    }\n    let buffer;\n    if (arrayBuffer instanceof Int16Array) {\n      buffer = arrayBuffer;\n    } else if (arrayBuffer instanceof ArrayBuffer) {\n      buffer = new Int16Array(arrayBuffer);\n    } else {\n      throw new Error(`argument must be Int16Array or ArrayBuffer`);\n    }\n    this.stream.port.postMessage({ event: 'write', buffer, trackId });\n    return buffer;\n  }\n\n  /**\n   * Gets the offset (sample count) of the currently playing stream\n   * @param {boolean} [interrupt]\n   * @returns {{trackId: string|null, offset: number, currentTime: number}}\n   */\n  async getTrackSampleOffset(interrupt = false) {\n    if (!this.stream) {\n      return null;\n    }\n    const requestId = crypto.randomUUID();\n    this.stream.port.postMessage({\n      event: interrupt ? 'interrupt' : 'offset',\n      requestId,\n    });\n    let trackSampleOffset;\n    while (!trackSampleOffset) {\n      trackSampleOffset = this.trackSampleOffsets[requestId];\n      await new Promise((r) => setTimeout(() => r(), 1));\n    }\n    const { trackId } = trackSampleOffset;\n    if (interrupt && trackId) {\n      this.interruptedTrackIds[trackId] = true;\n    }\n    return trackSampleOffset;\n  }\n\n  /**\n   * Strips the current stream and returns the sample offset of the audio\n   * @param {boolean} [interrupt]\n   * @returns {{trackId: string|null, offset: number, currentTime: number}}\n   */\n  async interrupt() {\n    return this.getTrackSampleOffset(true);\n  }\n}\n\nglobalThis.WavStreamPlayer = WavStreamPlayer;\n","const AudioProcessorWorklet = `\nclass AudioProcessor extends AudioWorkletProcessor {\n\n  constructor() {\n    super();\n    this.port.onmessage = this.receive.bind(this);\n    this.initialize();\n  }\n\n  initialize() {\n    this.foundAudio = false;\n    this.recording = false;\n    this.chunks = [];\n  }\n\n  /**\n   * Concatenates sampled chunks into channels\n   * Format is chunk[Left[], Right[]]\n   */\n  readChannelData(chunks, channel = -1, maxChannels = 9) {\n    let channelLimit;\n    if (channel !== -1) {\n      if (chunks[0] && chunks[0].length - 1 < channel) {\n        throw new Error(\n          \\`Channel \\${channel} out of range: max \\${chunks[0].length}\\`\n        );\n      }\n      channelLimit = channel + 1;\n    } else {\n      channel = 0;\n      channelLimit = Math.min(chunks[0] ? chunks[0].length : 1, maxChannels);\n    }\n    const channels = [];\n    for (let n = channel; n < channelLimit; n++) {\n      const length = chunks.reduce((sum, chunk) => {\n        return sum + chunk[n].length;\n      }, 0);\n      const buffers = chunks.map((chunk) => chunk[n]);\n      const result = new Float32Array(length);\n      let offset = 0;\n      for (let i = 0; i < buffers.length; i++) {\n        result.set(buffers[i], offset);\n        offset += buffers[i].length;\n      }\n      channels[n] = result;\n    }\n    return channels;\n  }\n\n  /**\n   * Combines parallel audio data into correct format,\n   * channels[Left[], Right[]] to float32Array[LRLRLRLR...]\n   */\n  formatAudioData(channels) {\n    if (channels.length === 1) {\n      // Simple case is only one channel\n      const float32Array = channels[0].slice();\n      const meanValues = channels[0].slice();\n      return { float32Array, meanValues };\n    } else {\n      const float32Array = new Float32Array(\n        channels[0].length * channels.length\n      );\n      const meanValues = new Float32Array(channels[0].length);\n      for (let i = 0; i < channels[0].length; i++) {\n        const offset = i * channels.length;\n        let meanValue = 0;\n        for (let n = 0; n < channels.length; n++) {\n          float32Array[offset + n] = channels[n][i];\n          meanValue += channels[n][i];\n        }\n        meanValues[i] = meanValue / channels.length;\n      }\n      return { float32Array, meanValues };\n    }\n  }\n\n  /**\n   * Converts 32-bit float data to 16-bit integers\n   */\n  floatTo16BitPCM(float32Array) {\n    const buffer = new ArrayBuffer(float32Array.length * 2);\n    const view = new DataView(buffer);\n    let offset = 0;\n    for (let i = 0; i < float32Array.length; i++, offset += 2) {\n      let s = Math.max(-1, Math.min(1, float32Array[i]));\n      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n    return buffer;\n  }\n\n  /**\n   * Retrieves the most recent amplitude values from the audio stream\n   * @param {number} channel\n   */\n  getValues(channel = -1) {\n    const channels = this.readChannelData(this.chunks, channel);\n    const { meanValues } = this.formatAudioData(channels);\n    return { meanValues, channels };\n  }\n\n  /**\n   * Exports chunks as an audio/wav file\n   */\n  export() {\n    const channels = this.readChannelData(this.chunks);\n    const { float32Array, meanValues } = this.formatAudioData(channels);\n    const audioData = this.floatTo16BitPCM(float32Array);\n    return {\n      meanValues: meanValues,\n      audio: {\n        bitsPerSample: 16,\n        channels: channels,\n        data: audioData,\n      },\n    };\n  }\n\n  receive(e) {\n    const { event, id } = e.data;\n    let receiptData = {};\n    switch (event) {\n      case 'start':\n        this.recording = true;\n        break;\n      case 'stop':\n        this.recording = false;\n        break;\n      case 'clear':\n        this.initialize();\n        break;\n      case 'export':\n        receiptData = this.export();\n        break;\n      case 'read':\n        receiptData = this.getValues();\n        break;\n      default:\n        break;\n    }\n    // Always send back receipt\n    this.port.postMessage({ event: 'receipt', id, data: receiptData });\n  }\n\n  sendChunk(chunk) {\n    const channels = this.readChannelData([chunk]);\n    const { float32Array, meanValues } = this.formatAudioData(channels);\n    const rawAudioData = this.floatTo16BitPCM(float32Array);\n    const monoAudioData = this.floatTo16BitPCM(meanValues);\n    this.port.postMessage({\n      event: 'chunk',\n      data: {\n        mono: monoAudioData,\n        raw: rawAudioData,\n      },\n    });\n  }\n\n  process(inputList, outputList, parameters) {\n    // Copy input to output (e.g. speakers)\n    // Note that this creates choppy sounds with Mac products\n    const sourceLimit = Math.min(inputList.length, outputList.length);\n    for (let inputNum = 0; inputNum < sourceLimit; inputNum++) {\n      const input = inputList[inputNum];\n      const output = outputList[inputNum];\n      const channelCount = Math.min(input.length, output.length);\n      for (let channelNum = 0; channelNum < channelCount; channelNum++) {\n        input[channelNum].forEach((sample, i) => {\n          output[channelNum][i] = sample;\n        });\n      }\n    }\n    const inputs = inputList[0];\n    // There's latency at the beginning of a stream before recording starts\n    // Make sure we actually receive audio data before we start storing chunks\n    let sliceIndex = 0;\n    if (!this.foundAudio) {\n      for (const channel of inputs) {\n        sliceIndex = 0; // reset for each channel\n        if (this.foundAudio) {\n          break;\n        }\n        if (channel) {\n          for (const value of channel) {\n            if (value !== 0) {\n              // find only one non-zero entry in any channel\n              this.foundAudio = true;\n              break;\n            } else {\n              sliceIndex++;\n            }\n          }\n        }\n      }\n    }\n    if (inputs && inputs[0] && this.foundAudio && this.recording) {\n      // We need to copy the TypedArray, because the \\`process\\`\n      // internals will reuse the same buffer to hold each input\n      const chunk = inputs.map((input) => input.slice(sliceIndex));\n      this.chunks.push(chunk);\n      this.sendChunk(chunk);\n    }\n    return true;\n  }\n}\n\nregisterProcessor('audio_processor', AudioProcessor);\n`;\n\nconst script = new Blob([AudioProcessorWorklet], {\n  type: 'application/javascript',\n});\nconst src = URL.createObjectURL(script);\nexport const AudioProcessorSrc = src;\n","import { AudioProcessorSrc } from './worklets/audio_processor.js';\nimport { AudioAnalysis } from './analysis/audio_analysis.js';\nimport { WavPacker } from './wav_packer.js';\n\n/**\n * Decodes audio into a wav file\n * @typedef {Object} DecodedAudioType\n * @property {Blob} blob\n * @property {string} url\n * @property {Float32Array} values\n * @property {AudioBuffer} audioBuffer\n */\n\n/**\n * Records live stream of user audio as PCM16 \"audio/wav\" data\n * @class\n */\nexport class WavRecorder {\n  /**\n   * Create a new WavRecorder instance\n   * @param {{sampleRate?: number, outputToSpeakers?: boolean, debug?: boolean}} [options]\n   * @returns {WavRecorder}\n   */\n  constructor({\n    sampleRate = 44100,\n    outputToSpeakers = false,\n    debug = false,\n  } = {}) {\n    // Script source\n    this.scriptSrc = AudioProcessorSrc;\n    // Config\n    this.sampleRate = sampleRate;\n    this.outputToSpeakers = outputToSpeakers;\n    this.debug = !!debug;\n    this._deviceChangeCallback = null;\n    this._devices = [];\n    // State variables\n    this.stream = null;\n    this.processor = null;\n    this.source = null;\n    this.node = null;\n    this.recording = false;\n    // Event handling with AudioWorklet\n    this._lastEventId = 0;\n    this.eventReceipts = {};\n    this.eventTimeout = 5000;\n    // Process chunks of audio\n    this._chunkProcessor = () => {};\n    this._chunkProcessorSize = void 0;\n    this._chunkProcessorBuffer = {\n      raw: new ArrayBuffer(0),\n      mono: new ArrayBuffer(0),\n    };\n  }\n\n  /**\n   * Decodes audio data from multiple formats to a Blob, url, Float32Array and AudioBuffer\n   * @param {Blob|Float32Array|Int16Array|ArrayBuffer|number[]} audioData\n   * @param {number} sampleRate\n   * @param {number} fromSampleRate\n   * @returns {Promise<DecodedAudioType>}\n   */\n  static async decode(audioData, sampleRate = 44100, fromSampleRate = -1) {\n    const context = new AudioContext({ sampleRate });\n    let arrayBuffer;\n    let blob;\n    if (audioData instanceof Blob) {\n      if (fromSampleRate !== -1) {\n        throw new Error(\n          `Can not specify \"fromSampleRate\" when reading from Blob`,\n        );\n      }\n      blob = audioData;\n      arrayBuffer = await blob.arrayBuffer();\n    } else if (audioData instanceof ArrayBuffer) {\n      if (fromSampleRate !== -1) {\n        throw new Error(\n          `Can not specify \"fromSampleRate\" when reading from ArrayBuffer`,\n        );\n      }\n      arrayBuffer = audioData;\n      blob = new Blob([arrayBuffer], { type: 'audio/wav' });\n    } else {\n      let float32Array;\n      let data;\n      if (audioData instanceof Int16Array) {\n        data = audioData;\n        float32Array = new Float32Array(audioData.length);\n        for (let i = 0; i < audioData.length; i++) {\n          float32Array[i] = audioData[i] / 0x8000;\n        }\n      } else if (audioData instanceof Float32Array) {\n        float32Array = audioData;\n      } else if (audioData instanceof Array) {\n        float32Array = new Float32Array(audioData);\n      } else {\n        throw new Error(\n          `\"audioData\" must be one of: Blob, Float32Arrray, Int16Array, ArrayBuffer, Array<number>`,\n        );\n      }\n      if (fromSampleRate === -1) {\n        throw new Error(\n          `Must specify \"fromSampleRate\" when reading from Float32Array, In16Array or Array`,\n        );\n      } else if (fromSampleRate < 3000) {\n        throw new Error(`Minimum \"fromSampleRate\" is 3000 (3kHz)`);\n      }\n      if (!data) {\n        data = WavPacker.floatTo16BitPCM(float32Array);\n      }\n      const audio = {\n        bitsPerSample: 16,\n        channels: [float32Array],\n        data,\n      };\n      const packer = new WavPacker();\n      const result = packer.pack(fromSampleRate, audio);\n      blob = result.blob;\n      arrayBuffer = await blob.arrayBuffer();\n    }\n    const audioBuffer = await context.decodeAudioData(arrayBuffer);\n    const values = audioBuffer.getChannelData(0);\n    const url = URL.createObjectURL(blob);\n    return {\n      blob,\n      url,\n      values,\n      audioBuffer,\n    };\n  }\n\n  /**\n   * Logs data in debug mode\n   * @param {...any} arguments\n   * @returns {true}\n   */\n  log() {\n    if (this.debug) {\n      this.log(...arguments);\n    }\n    return true;\n  }\n\n  /**\n   * Retrieves the current sampleRate for the recorder\n   * @returns {number}\n   */\n  getSampleRate() {\n    return this.sampleRate;\n  }\n\n  /**\n   * Retrieves the current status of the recording\n   * @returns {\"ended\"|\"paused\"|\"recording\"}\n   */\n  getStatus() {\n    if (!this.processor) {\n      return 'ended';\n    } else if (!this.recording) {\n      return 'paused';\n    } else {\n      return 'recording';\n    }\n  }\n\n  /**\n   * Sends an event to the AudioWorklet\n   * @private\n   * @param {string} name\n   * @param {{[key: string]: any}} data\n   * @param {AudioWorkletNode} [_processor]\n   * @returns {Promise<{[key: string]: any}>}\n   */\n  async _event(name, data = {}, _processor = null) {\n    _processor = _processor || this.processor;\n    if (!_processor) {\n      throw new Error('Can not send events without recording first');\n    }\n    const message = {\n      event: name,\n      id: this._lastEventId++,\n      data,\n    };\n    _processor.port.postMessage(message);\n    const t0 = new Date().valueOf();\n    while (!this.eventReceipts[message.id]) {\n      if (new Date().valueOf() - t0 > this.eventTimeout) {\n        throw new Error(`Timeout waiting for \"${name}\" event`);\n      }\n      await new Promise((res) => setTimeout(() => res(true), 1));\n    }\n    const payload = this.eventReceipts[message.id];\n    delete this.eventReceipts[message.id];\n    return payload;\n  }\n\n  /**\n   * Sets device change callback, remove if callback provided is `null`\n   * @param {(Array<MediaDeviceInfo & {default: boolean}>): void|null} callback\n   * @returns {true}\n   */\n  listenForDeviceChange(callback) {\n    if (callback === null && this._deviceChangeCallback) {\n      navigator.mediaDevices.removeEventListener(\n        'devicechange',\n        this._deviceChangeCallback,\n      );\n      this._deviceChangeCallback = null;\n    } else if (callback !== null) {\n      // Basically a debounce; we only want this called once when devices change\n      // And we only want the most recent callback() to be executed\n      // if a few are operating at the same time\n      let lastId = 0;\n      let lastDevices = [];\n      const serializeDevices = (devices) =>\n        devices\n          .map((d) => d.deviceId)\n          .sort()\n          .join(',');\n      const cb = async () => {\n        let id = ++lastId;\n        const devices = await this.listDevices();\n        if (id === lastId) {\n          if (serializeDevices(lastDevices) !== serializeDevices(devices)) {\n            lastDevices = devices;\n            callback(devices.slice());\n          }\n        }\n      };\n      navigator.mediaDevices.addEventListener('devicechange', cb);\n      cb();\n      this._deviceChangeCallback = cb;\n    }\n    return true;\n  }\n\n  /**\n   * Manually request permission to use the microphone\n   * @returns {Promise<true>}\n   */\n  async requestPermission() {\n    const permissionStatus = await navigator.permissions.query({\n      name: 'microphone',\n    });\n    if (permissionStatus.state === 'denied') {\n      window.alert('You must grant microphone access to use this feature.');\n    } else if (permissionStatus.state === 'prompt') {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: true,\n        });\n        const tracks = stream.getTracks();\n        tracks.forEach((track) => track.stop());\n      } catch (e) {\n        window.alert('You must grant microphone access to use this feature.');\n      }\n    }\n    return true;\n  }\n\n  /**\n   * List all eligible devices for recording, will request permission to use microphone\n   * @returns {Promise<Array<MediaDeviceInfo & {default: boolean}>>}\n   */\n  async listDevices() {\n    if (\n      !navigator.mediaDevices ||\n      !('enumerateDevices' in navigator.mediaDevices)\n    ) {\n      throw new Error('Could not request user devices');\n    }\n    await this.requestPermission();\n    const devices = await navigator.mediaDevices.enumerateDevices();\n    const audioDevices = devices.filter(\n      (device) => device.kind === 'audioinput',\n    );\n    const defaultDeviceIndex = audioDevices.findIndex(\n      (device) => device.deviceId === 'default',\n    );\n    const deviceList = [];\n    if (defaultDeviceIndex !== -1) {\n      let defaultDevice = audioDevices.splice(defaultDeviceIndex, 1)[0];\n      let existingIndex = audioDevices.findIndex(\n        (device) => device.groupId === defaultDevice.groupId,\n      );\n      if (existingIndex !== -1) {\n        defaultDevice = audioDevices.splice(existingIndex, 1)[0];\n      }\n      defaultDevice.default = true;\n      deviceList.push(defaultDevice);\n    }\n    return deviceList.concat(audioDevices);\n  }\n\n  /**\n   * Begins a recording session and requests microphone permissions if not already granted\n   * Microphone recording indicator will appear on browser tab but status will be \"paused\"\n   * @param {string} [deviceId] if no device provided, default device will be used\n   * @returns {Promise<true>}\n   */\n  async begin(deviceId) {\n    if (this.processor) {\n      throw new Error(\n        `Already connected: please call .end() to start a new session`,\n      );\n    }\n\n    if (\n      !navigator.mediaDevices ||\n      !('getUserMedia' in navigator.mediaDevices)\n    ) {\n      throw new Error('Could not request user media');\n    }\n    try {\n      const config = { audio: true };\n      if (deviceId) {\n        config.audio = { deviceId: { exact: deviceId } };\n      }\n      this.stream = await navigator.mediaDevices.getUserMedia(config);\n    } catch (err) {\n      throw new Error('Could not start media stream');\n    }\n\n    const context = new AudioContext({ sampleRate: this.sampleRate });\n    const source = context.createMediaStreamSource(this.stream);\n    // Load and execute the module script.\n    try {\n      await context.audioWorklet.addModule(this.scriptSrc);\n    } catch (e) {\n      console.error(e);\n      throw new Error(`Could not add audioWorklet module: ${this.scriptSrc}`);\n    }\n    const processor = new AudioWorkletNode(context, 'audio_processor');\n    processor.port.onmessage = (e) => {\n      const { event, id, data } = e.data;\n      if (event === 'receipt') {\n        this.eventReceipts[id] = data;\n      } else if (event === 'chunk') {\n        if (this._chunkProcessorSize) {\n          const buffer = this._chunkProcessorBuffer;\n          this._chunkProcessorBuffer = {\n            raw: WavPacker.mergeBuffers(buffer.raw, data.raw),\n            mono: WavPacker.mergeBuffers(buffer.mono, data.mono),\n          };\n          if (\n            this._chunkProcessorBuffer.mono.byteLength >=\n            this._chunkProcessorSize\n          ) {\n            this._chunkProcessor(this._chunkProcessorBuffer);\n            this._chunkProcessorBuffer = {\n              raw: new ArrayBuffer(0),\n              mono: new ArrayBuffer(0),\n            };\n          }\n        } else {\n          this._chunkProcessor(data);\n        }\n      }\n    };\n\n    const node = source.connect(processor);\n    const analyser = context.createAnalyser();\n    analyser.fftSize = 8192;\n    analyser.smoothingTimeConstant = 0.1;\n    node.connect(analyser);\n    if (this.outputToSpeakers) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        'Warning: Output to speakers may affect sound quality,\\n' +\n          'especially due to system audio feedback preventative measures.\\n' +\n          'use only for debugging',\n      );\n      analyser.connect(context.destination);\n    }\n\n    this.source = source;\n    this.node = node;\n    this.analyser = analyser;\n    this.processor = processor;\n    return true;\n  }\n\n  /**\n   * Gets the current frequency domain data from the recording track\n   * @param {\"frequency\"|\"music\"|\"voice\"} [analysisType]\n   * @param {number} [minDecibels] default -100\n   * @param {number} [maxDecibels] default -30\n   * @returns {import('./analysis/audio_analysis.js').AudioAnalysisOutputType}\n   */\n  getFrequencies(\n    analysisType = 'frequency',\n    minDecibels = -100,\n    maxDecibels = -30,\n  ) {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    }\n    return AudioAnalysis.getFrequencies(\n      this.analyser,\n      this.sampleRate,\n      null,\n      analysisType,\n      minDecibels,\n      maxDecibels,\n    );\n  }\n\n  /**\n   * Pauses the recording\n   * Keeps microphone stream open but halts storage of audio\n   * @returns {Promise<true>}\n   */\n  async pause() {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    } else if (!this.recording) {\n      throw new Error('Already paused: please call .record() first');\n    }\n    if (this._chunkProcessorBuffer.raw.byteLength) {\n      this._chunkProcessor(this._chunkProcessorBuffer);\n    }\n    this.log('Pausing ...');\n    await this._event('stop');\n    this.recording = false;\n    return true;\n  }\n\n  /**\n   * Start recording stream and storing to memory from the connected audio source\n   * @param {(data: { mono: Int16Array; raw: Int16Array }) => any} [chunkProcessor]\n   * @param {number} [chunkSize] chunkProcessor will not be triggered until this size threshold met in mono audio\n   * @returns {Promise<true>}\n   */\n  async record(chunkProcessor = () => {}, chunkSize = 8192) {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    } else if (this.recording) {\n      throw new Error('Already recording: please call .pause() first');\n    } else if (typeof chunkProcessor !== 'function') {\n      throw new Error(`chunkProcessor must be a function`);\n    }\n    this._chunkProcessor = chunkProcessor;\n    this._chunkProcessorSize = chunkSize;\n    this._chunkProcessorBuffer = {\n      raw: new ArrayBuffer(0),\n      mono: new ArrayBuffer(0),\n    };\n    this.log('Recording ...');\n    await this._event('start');\n    this.recording = true;\n    return true;\n  }\n\n  /**\n   * Clears the audio buffer, empties stored recording\n   * @returns {Promise<true>}\n   */\n  async clear() {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    }\n    await this._event('clear');\n    return true;\n  }\n\n  /**\n   * Reads the current audio stream data\n   * @returns {Promise<{meanValues: Float32Array, channels: Array<Float32Array>}>}\n   */\n  async read() {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    }\n    this.log('Reading ...');\n    const result = await this._event('read');\n    return result;\n  }\n\n  /**\n   * Saves the current audio stream to a file\n   * @param {boolean} [force] Force saving while still recording\n   * @returns {Promise<import('./wav_packer.js').WavPackerAudioType>}\n   */\n  async save(force = false) {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    }\n    if (!force && this.recording) {\n      throw new Error(\n        'Currently recording: please call .pause() first, or call .save(true) to force',\n      );\n    }\n    this.log('Exporting ...');\n    const exportData = await this._event('export');\n    const packer = new WavPacker();\n    const result = packer.pack(this.sampleRate, exportData.audio);\n    return result;\n  }\n\n  /**\n   * Ends the current recording session and saves the result\n   * @returns {Promise<import('./wav_packer.js').WavPackerAudioType>}\n   */\n  async end() {\n    if (!this.processor) {\n      throw new Error('Session ended: please call .begin() first');\n    }\n\n    const _processor = this.processor;\n\n    this.log('Stopping ...');\n    await this._event('stop');\n    this.recording = false;\n    const tracks = this.stream.getTracks();\n    tracks.forEach((track) => track.stop());\n\n    this.log('Exporting ...');\n    const exportData = await this._event('export', {}, _processor);\n\n    this.processor.disconnect();\n    this.source.disconnect();\n    this.node.disconnect();\n    this.analyser.disconnect();\n    this.stream = null;\n    this.processor = null;\n    this.source = null;\n    this.node = null;\n\n    const packer = new WavPacker();\n    const result = packer.pack(this.sampleRate, exportData.audio);\n    return result;\n  }\n\n  /**\n   * Performs a full cleanup of WavRecorder instance\n   * Stops actively listening via microphone and removes existing listeners\n   * @returns {Promise<true>}\n   */\n  async quit() {\n    this.listenForDeviceChange(null);\n    if (this.processor) {\n      await this.end();\n    }\n    return true;\n  }\n}\n\nglobalThis.WavRecorder = WavRecorder;\n"],"names":["WavPacker","floatTo16BitPCM","float32Array","buffer","ArrayBuffer","length","view","DataView","offset","i","s","Math","max","min","setInt16","mergeBuffers","leftBuffer","rightBuffer","tmpArray","Uint8Array","byteLength","set","_packData","size","arg","pack","sampleRate","audio","bitsPerSample","Error","channels","data","output","this","blob","Blob","type","url","URL","createObjectURL","channelCount","duration","globalThis","octave8Frequencies","octave8FrequencyLabels","noteFrequencies","noteFrequencyLabels","f","freq","push","pow","voiceFrequencyRange","voiceFrequencies","filter","_","voiceFrequencyLabels","AudioAnalysis","getFrequencies","analyser","fftResult","analysisType","minDecibels","maxDecibels","Float32Array","frequencyBinCount","getFloatFrequencyData","nyquistFrequency","frequencyStep","outputValues","frequencies","labels","useFrequencies","aggregateOutput","Array","fill","frequency","amplitude","n","from","map","toFixed","normalizedOutput","v","values","constructor","audioElement","audioBuffer","fftResults","offlineAudioContext","OfflineAudioContext","source","createBufferSource","createAnalyser","fftSize","smoothingTimeConstant","connect","renderQuantumInSeconds","durationInSeconds","analyze","index","suspendTime","suspend","then","startRendering","resume","start","context","audioContext","AudioContext","track","createMediaElementSource","destination","pct","currentTime","resumeIfSuspended","state","script","StreamProcessorSrc","WavStreamPlayer","scriptSrc","stream","trackSampleOffsets","interruptedTrackIds","audioWorklet","addModule","e","console","error","_start","streamNode","AudioWorkletNode","port","onmessage","event","disconnect","requestId","trackId","add16BitPCM","arrayBuffer","Int16Array","postMessage","getTrackSampleOffset","interrupt","crypto","randomUUID","trackSampleOffset","Promise","r","setTimeout","AudioProcessorSrc","WavRecorder","outputToSpeakers","debug","_deviceChangeCallback","_devices","processor","node","recording","_lastEventId","eventReceipts","eventTimeout","_chunkProcessor","_chunkProcessorSize","_chunkProcessorBuffer","raw","mono","decode","audioData","fromSampleRate","decodeAudioData","getChannelData","log","arguments","getSampleRate","getStatus","_event","name","_processor","message","id","t0","Date","valueOf","res","payload","listenForDeviceChange","callback","navigator","mediaDevices","removeEventListener","lastId","lastDevices","serializeDevices","devices","d","deviceId","sort","join","cb","async","listDevices","slice","addEventListener","requestPermission","permissionStatus","permissions","query","window","alert","getUserMedia","getTracks","forEach","stop","audioDevices","enumerateDevices","device","kind","defaultDeviceIndex","findIndex","deviceList","defaultDevice","splice","existingIndex","groupId","default","concat","begin","config","exact","err","createMediaStreamSource","warn","pause","record","chunkProcessor","chunkSize","clear","read","save","force","exportData","end","quit"],"mappings":"gPAcO,MAAMA,EAMX,sBAAOC,CAAgBC,GACrB,MAAMC,EAAS,IAAIC,YAAkC,EAAtBF,EAAaG,QACtCC,EAAO,IAAIC,SAASJ,GAC1B,IAAIK,EAAS,EACb,IAAK,IAAIC,EAAI,EAAGA,EAAIP,EAAaG,OAAQI,IAAKD,GAAU,EAAG,CACzD,IAAIE,EAAIC,KAAKC,KAAK,EAAGD,KAAKE,IAAI,EAAGX,EAAaO,KAC9CH,EAAKQ,SAASN,EAAQE,EAAI,EAAQ,MAAJA,EAAiB,MAAJA,GAAY,EAC7D,CACI,OAAOP,CACX,CAQE,mBAAOY,CAAaC,EAAYC,GAC9B,MAAMC,EAAW,IAAIC,WACnBH,EAAWI,WAAaH,EAAYG,YAItC,OAFAF,EAASG,IAAI,IAAIF,WAAWH,GAAa,GACzCE,EAASG,IAAI,IAAIF,WAAWF,GAAcD,EAAWI,YAC9CF,EAASf,MACpB,CASE,SAAAmB,CAAUC,EAAMC,GACd,MAAO,CACL,IAAIL,WAAW,CAACK,EAAKA,GAAO,IAC5B,IAAIL,WAAW,CAACK,EAAKA,GAAO,EAAGA,GAAO,GAAIA,GAAO,MACjDD,EACN,CAQE,IAAAE,CAAKC,EAAYC,GACf,IAAKA,GAAOC,cACV,MAAM,IAAIC,MAAM,2BACX,IAAKF,GAAOG,SACjB,MAAM,IAAID,MAAM,sBACX,IAAKF,GAAOI,KACjB,MAAM,IAAIF,MAAM,kBAElB,MAAMD,cAAEA,EAAaE,SAAEA,EAAQC,KAAEA,GAASJ,EACpCK,EAAS,CAEb,OACAC,KAAKX,UACH,EACA,IAEF,OAEA,OACAW,KAAKX,UAAU,EAAG,IAClBW,KAAKX,UAAU,EAAG,GAClBW,KAAKX,UAAU,EAAGQ,EAASzB,QAC3B4B,KAAKX,UAAU,EAAGI,GAClBO,KAAKX,UAAU,EAAII,EAAaI,EAASzB,OAASuB,EAAiB,GACnEK,KAAKX,UAAU,EAAIQ,EAASzB,OAASuB,EAAiB,GACtDK,KAAKX,UAAU,EAAGM,GAElB,OACAK,KAAKX,UACH,EACCQ,EAAS,GAAGzB,OAASyB,EAASzB,OAASuB,EAAiB,GAE3DG,GAEIG,EAAO,IAAIC,KAAKH,EAAQ,CAAEI,KAAM,eAEtC,MAAO,CACLF,OACAG,IAHUC,IAAIC,gBAAgBL,GAI9BM,aAAcV,EAASzB,OACvBqB,aACAe,SAAUV,EAAKX,YAAcU,EAASzB,OAASqB,EAAa,GAElE,EAGAgB,WAAW1C,UAAYA,ECxGvB,MAAM2C,EAAqB,CACzB,QAAS,QAAS,QAAS,QAAS,QAAS,QAAS,QAAS,QAC/D,QAAS,KAAQ,QAAS,SAItBC,EAAyB,CAC7B,IACA,KACA,IACA,KACA,IACA,IACA,KACA,IACA,KACA,IACA,KACA,KAOWC,EAAkB,GAClBC,EAAsB,GACnC,IAAK,IAAIrC,EAAI,EAAGA,GAAK,EAAGA,IACtB,IAAK,IAAIsC,EAAI,EAAGA,EAAIJ,EAAmBtC,OAAQ0C,IAAK,CAClD,MAAMC,EAAOL,EAAmBI,GAChCF,EAAgBI,KAAKD,EAAOrC,KAAKuC,IAAI,EAAG,EAAIzC,IAC5CqC,EAAoBG,KAAKL,EAAuBG,GAAKtC,EACzD,CAOA,MAAM0C,EAAsB,CAAC,GAAM,KACtBC,EAAmBP,EAAgBQ,QAAO,CAACC,EAAG7C,IAEvDoC,EAAgBpC,GAAK0C,EAAoB,IACzCN,EAAgBpC,GAAK0C,EAAoB,KAGhCI,EAAuBT,EAAoBO,QAAO,CAACC,EAAG7C,IAE/DoC,EAAgBpC,GAAK0C,EAAoB,IACzCN,EAAgBpC,GAAK0C,EAAoB,KCtCtC,MAAMK,EAYX,qBAAOC,CACLC,EACAhC,EACAiC,EACAC,EAAe,YACfC,GAAc,IACdC,GAAc,IAETH,IACHA,EAAY,IAAII,aAAaL,EAASM,mBACtCN,EAASO,sBAAsBN,IAEjC,MAAMO,EAAmBxC,EAAa,EAChCyC,EAAiB,EAAIR,EAAUtD,OAAU6D,EAC/C,IAAIE,EACAC,EACAC,EACJ,GAAqB,UAAjBV,GAA6C,UAAjBA,EAA0B,CACxD,MAAMW,EACa,UAAjBX,EAA2BR,EAAmBP,EAC1C2B,EAAkBC,MAAMF,EAAelE,QAAQqE,KAAKb,GAC1D,IAAK,IAAIpD,EAAI,EAAGA,EAAIkD,EAAUtD,OAAQI,IAAK,CACzC,MAAMkE,EAAYlE,EAAI0D,EAChBS,EAAYjB,EAAUlD,GAC5B,IAAK,IAAIoE,EAAIN,EAAelE,OAAS,EAAGwE,GAAK,EAAGA,IAC9C,GAAIF,EAAYJ,EAAeM,GAAI,CACjCL,EAAgBK,GAAKlE,KAAKC,IAAI4D,EAAgBK,GAAID,GAClD,KACZ,CAEA,CACMR,EAAeI,EACfH,EACmB,UAAjBT,EAA2BR,EAAmBP,EAChDyB,EACmB,UAAjBV,EAA2BL,EAAuBT,CAC1D,MACMsB,EAAeK,MAAMK,KAAKnB,GAC1BU,EAAcD,EAAaW,KAAI,CAACzB,EAAG7C,IAAM0D,EAAgB1D,IACzD6D,EAASD,EAAYU,KAAKhC,GAAM,GAAGA,EAAEiC,QAAQ,UAG/C,MAAMC,EAAmBb,EAAaW,KAAKG,GAClCvE,KAAKC,IACV,EACAD,KAAKE,KAAKqE,EAAIrB,IAAgBC,EAAcD,GAAc,MAI9D,MAAO,CACLsB,OAFa,IAAIpB,aAAakB,GAG9BZ,cACAC,SAEN,CAQE,WAAAc,CAAYC,EAAcC,EAAc,MAEtC,GADArD,KAAKsD,WAAa,GACdD,EAAa,CASf,MAAMjF,OAAEA,EAAMqB,WAAEA,GAAe4D,EACzBE,EAAsB,IAAIC,oBAAoB,CAClDpF,SACAqB,eAEIgE,EAASF,EAAoBG,qBACnCD,EAAOvF,OAASmF,EAChB,MAAM5B,EAAW8B,EAAoBI,iBACrClC,EAASmC,QAAU,KACnBnC,EAASoC,sBAAwB,GACjCJ,EAAOK,QAAQrC,GAGf,MAAMsC,EAAyB,EAAI,GAC7BC,EAAoB5F,EAASqB,EAC7BwE,EAAWC,IACf,MAAMC,EAAcJ,EAAyBG,EACzCC,EAAcH,GAChBT,EAAoBa,QAAQD,GAAaE,MAAK,KAC5C,MAAM3C,EAAY,IAAII,aAAaL,EAASM,mBAC5CN,EAASO,sBAAsBN,GAC/B1B,KAAKsD,WAAWtC,KAAKU,GACrBuC,EAAQC,EAAQ,EAAE,IAGR,IAAVA,EACFX,EAAoBe,iBAEpBf,EAAoBgB,QAC9B,EAEMd,EAAOe,MAAM,GACbP,EAAQ,GACRjE,KAAKN,MAAQ0D,EACbpD,KAAKyE,QAAUlB,EACfvD,KAAKyB,SAAWA,EAChBzB,KAAKP,WAAaA,EAClBO,KAAKqD,YAAcA,CACzB,KAAW,CACL,MAAMqB,EAAe,IAAIC,aACnBC,EAAQF,EAAaG,yBAAyBzB,GAC9C3B,EAAWiD,EAAaf,iBAC9BlC,EAASmC,QAAU,KACnBnC,EAASoC,sBAAwB,GACjCe,EAAMd,QAAQrC,GACdA,EAASqC,QAAQY,EAAaI,aAC9B9E,KAAKN,MAAQ0D,EACbpD,KAAKyE,QAAUC,EACf1E,KAAKyB,SAAWA,EAChBzB,KAAKP,WAAaO,KAAKyE,QAAQhF,WAC/BO,KAAKqD,YAAc,IACzB,CACA,CASE,cAAA7B,CACEG,EAAe,YACfC,GAAc,IACdC,GAAc,IAEd,IAAIH,EAAY,KAChB,GAAI1B,KAAKqD,aAAerD,KAAKsD,WAAWlF,OAAQ,CAC9C,MAAM2G,EAAM/E,KAAKN,MAAMsF,YAAchF,KAAKN,MAAMc,SAC1C0D,EAAQxF,KAAKE,IAChBmG,EAAM/E,KAAKsD,WAAWlF,OAAU,EACjC4B,KAAKsD,WAAWlF,OAAS,GAE3BsD,EAAY1B,KAAKsD,WAAWY,EAClC,CACI,OAAO3C,EAAcC,eACnBxB,KAAKyB,SACLzB,KAAKP,WACLiC,EACAC,EACAC,EACAC,EAEN,CAOE,uBAAMoD,GAIJ,MAH2B,cAAvBjF,KAAKyE,QAAQS,aACTlF,KAAKyE,QAAQF,UAEd,CACX,EAGA9D,WAAWc,cAAgBA,EC1MpB,MA2FD4D,EAAS,IAAIjF,KAAK,CA3Fc,i2FA2FY,CAChDC,KAAM,2BAGKiF,EADD/E,IAAIC,gBAAgB6E,GCvFzB,MAAME,EAMX,WAAAlC,EAAY1D,WAAEA,EAAa,OAAU,CAAA,GACnCO,KAAKsF,UAAYF,EACjBpF,KAAKP,WAAaA,EAClBO,KAAKyE,QAAU,KACfzE,KAAKuF,OAAS,KACdvF,KAAKyB,SAAW,KAChBzB,KAAKwF,mBAAqB,CAAE,EAC5BxF,KAAKyF,oBAAsB,CAAE,CACjC,CAME,aAAM3B,GACJ9D,KAAKyE,QAAU,IAAIE,aAAa,CAAElF,WAAYO,KAAKP,aACxB,cAAvBO,KAAKyE,QAAQS,aACTlF,KAAKyE,QAAQF,SAErB,UACQvE,KAAKyE,QAAQiB,aAAaC,UAAU3F,KAAKsF,UAChD,CAAC,MAAOM,GAEP,MADAC,QAAQC,MAAMF,GACR,IAAIhG,MAAM,sCAAsCI,KAAKsF,YACjE,CACI,MAAM7D,EAAWzB,KAAKyE,QAAQd,iBAI9B,OAHAlC,EAASmC,QAAU,KACnBnC,EAASoC,sBAAwB,GACjC7D,KAAKyB,SAAWA,GACT,CACX,CASE,cAAAD,CACEG,EAAe,YACfC,GAAc,IACdC,GAAc,IAEd,IAAK7B,KAAKyB,SACR,MAAM,IAAI7B,MAAM,+CAElB,OAAO2B,EAAcC,eACnBxB,KAAKyB,SACLzB,KAAKP,WACL,KACAkC,EACAC,EACAC,EAEN,CAOE,MAAAkE,GACE,MAAMC,EAAa,IAAIC,iBAAiBjG,KAAKyE,QAAS,oBAgBtD,OAfAuB,EAAWlC,QAAQ9D,KAAKyE,QAAQK,aAChCkB,EAAWE,KAAKC,UAAaP,IAC3B,MAAMQ,MAAEA,GAAUR,EAAE9F,KACpB,GAAc,SAAVsG,EACFJ,EAAWK,aACXrG,KAAKuF,OAAS,UACT,GAAc,WAAVa,EAAoB,CAC7B,MAAME,UAAEA,EAASC,QAAEA,EAAOhI,OAAEA,GAAWqH,EAAE9F,KACnCkF,EAAczG,EAASyB,KAAKP,WAClCO,KAAKwF,mBAAmBc,GAAa,CAAEC,UAAShI,SAAQyG,cAChE,GAEIhF,KAAKyB,SAAS4E,aACdL,EAAWlC,QAAQ9D,KAAKyB,UACxBzB,KAAKuF,OAASS,GACP,CACX,CASE,WAAAQ,CAAYC,EAAaF,EAAU,WACjC,GAAuB,iBAAZA,EACT,MAAM,IAAI3G,MAAM,4BACX,GAAII,KAAKyF,oBAAoBc,GAClC,OAKF,IAAIrI,EACJ,GAJK8B,KAAKuF,QACRvF,KAAK+F,SAGHU,aAAuBC,WACzBxI,EAASuI,MACJ,MAAIA,aAAuBtI,aAGhC,MAAM,IAAIyB,MAAM,8CAFhB1B,EAAS,IAAIwI,WAAWD,EAG9B,CAEI,OADAzG,KAAKuF,OAAOW,KAAKS,YAAY,CAAEP,MAAO,QAASlI,SAAQqI,YAChDrI,CACX,CAOE,0BAAM0I,CAAqBC,GAAY,GACrC,IAAK7G,KAAKuF,OACR,OAAO,KAET,MAAMe,EAAYQ,OAAOC,aAKzB,IAAIC,EACJ,IALAhH,KAAKuF,OAAOW,KAAKS,YAAY,CAC3BP,MAAOS,EAAY,YAAc,SACjCP,eAGMU,GACNA,EAAoBhH,KAAKwF,mBAAmBc,SACtC,IAAIW,SAASC,GAAMC,YAAW,IAAMD,KAAK,KAEjD,MAAMX,QAAEA,GAAYS,EAIpB,OAHIH,GAAaN,IACfvG,KAAKyF,oBAAoBc,IAAW,GAE/BS,CACX,CAOE,eAAMH,GACJ,OAAO7G,KAAK4G,sBAAqB,EACrC,EAGAnG,WAAW4E,gBAAkBA,EC/J7B,MAiNMF,EAAS,IAAIjF,KAAK,CAjNM,irMAiNmB,CAC/CC,KAAM,2BAGKiH,EADD/G,IAAIC,gBAAgB6E,GCnMzB,MAAMkC,EAMX,WAAAlE,EAAY1D,WACVA,EAAa,MAAK6H,iBAClBA,GAAmB,EAAKC,MACxBA,GAAQ,GACN,IAEFvH,KAAKsF,UAAY8B,EAEjBpH,KAAKP,WAAaA,EAClBO,KAAKsH,iBAAmBA,EACxBtH,KAAKuH,QAAUA,EACfvH,KAAKwH,sBAAwB,KAC7BxH,KAAKyH,SAAW,GAEhBzH,KAAKuF,OAAS,KACdvF,KAAK0H,UAAY,KACjB1H,KAAKyD,OAAS,KACdzD,KAAK2H,KAAO,KACZ3H,KAAK4H,WAAY,EAEjB5H,KAAK6H,aAAe,EACpB7H,KAAK8H,cAAgB,CAAE,EACvB9H,KAAK+H,aAAe,IAEpB/H,KAAKgI,gBAAkB,OACvBhI,KAAKiI,yBAAsB,EAC3BjI,KAAKkI,sBAAwB,CAC3BC,IAAK,IAAIhK,YAAY,GACrBiK,KAAM,IAAIjK,YAAY,GAE5B,CASE,mBAAakK,CAAOC,EAAW7I,EAAa,MAAO8I,GAAiB,GAClE,MAAM9D,EAAU,IAAIE,aAAa,CAAElF,eACnC,IAAIgH,EACAxG,EACJ,GAAIqI,aAAqBpI,KAAM,CAC7B,IAAwB,IAApBqI,EACF,MAAM,IAAI3I,MACR,2DAGJK,EAAOqI,EACP7B,QAAoBxG,EAAKwG,aAC/B,MAAW,GAAI6B,aAAqBnK,YAAa,CAC3C,IAAwB,IAApBoK,EACF,MAAM,IAAI3I,MACR,kEAGJ6G,EAAc6B,EACdrI,EAAO,IAAIC,KAAK,CAACuG,GAAc,CAAEtG,KAAM,aAC7C,KAAW,CACL,IAAIlC,EACA6B,EACJ,GAAIwI,aAAqB5B,WAAY,CACnC5G,EAAOwI,EACPrK,EAAe,IAAI6D,aAAawG,EAAUlK,QAC1C,IAAK,IAAII,EAAI,EAAGA,EAAI8J,EAAUlK,OAAQI,IACpCP,EAAaO,GAAK8J,EAAU9J,GAAK,KAE3C,MAAa,GAAI8J,aAAqBxG,aAC9B7D,EAAeqK,MACV,MAAIA,aAAqB9F,OAG9B,MAAM,IAAI5C,MACR,2FAHF3B,EAAe,IAAI6D,aAAawG,EAKxC,CACM,IAAwB,IAApBC,EACF,MAAM,IAAI3I,MACR,oFAEG,GAAI2I,EAAiB,IAC1B,MAAM,IAAI3I,MAAM,2CAEbE,IACHA,EAAO/B,EAAUC,gBAAgBC,IAEnC,MAAMyB,EAAQ,CACZC,cAAe,GACfE,SAAU,CAAC5B,GACX6B,QAIFG,GAFe,IAAIlC,GACGyB,KAAK+I,EAAgB7I,GAC7BO,KACdwG,QAAoBxG,EAAKwG,aAC/B,CACI,MAAMpD,QAAoBoB,EAAQ+D,gBAAgB/B,GAC5CvD,EAASG,EAAYoF,eAAe,GAE1C,MAAO,CACLxI,OACAG,IAHUC,IAAIC,gBAAgBL,GAI9BiD,SACAG,cAEN,CAOE,GAAAqF,GAIE,OAHI1I,KAAKuH,OACPvH,KAAK0I,OAAOC,YAEP,CACX,CAME,aAAAC,GACE,OAAO5I,KAAKP,UAChB,CAME,SAAAoJ,GACE,OAAK7I,KAAK0H,UAEE1H,KAAK4H,UAGR,YAFA,SAFA,OAMb,CAUE,YAAMkB,CAAOC,EAAMjJ,EAAO,CAAA,EAAIkJ,EAAa,MAEzC,KADAA,EAAaA,GAAchJ,KAAK0H,WAE9B,MAAM,IAAI9H,MAAM,+CAElB,MAAMqJ,EAAU,CACd7C,MAAO2C,EACPG,GAAIlJ,KAAK6H,eACT/H,QAEFkJ,EAAW9C,KAAKS,YAAYsC,GAC5B,MAAME,GAAK,IAAIC,MAAOC,UACtB,MAAQrJ,KAAK8H,cAAcmB,EAAQC,KAAK,CACtC,IAAI,IAAIE,MAAOC,UAAYF,EAAKnJ,KAAK+H,aACnC,MAAM,IAAInI,MAAM,wBAAwBmJ,kBAEpC,IAAI9B,SAASqC,GAAQnC,YAAW,IAAMmC,GAAI,IAAO,IAC7D,CACI,MAAMC,EAAUvJ,KAAK8H,cAAcmB,EAAQC,IAE3C,cADOlJ,KAAK8H,cAAcmB,EAAQC,IAC3BK,CACX,CAOE,qBAAAC,CAAsBC,GACpB,GAAiB,OAAbA,GAAqBzJ,KAAKwH,sBAC5BkC,UAAUC,aAAaC,oBACrB,eACA5J,KAAKwH,uBAEPxH,KAAKwH,sBAAwB,UACxB,GAAiB,OAAbiC,EAAmB,CAI5B,IAAII,EAAS,EACTC,EAAc,GAClB,MAAMC,EAAoBC,GACxBA,EACGlH,KAAKmH,GAAMA,EAAEC,WACbC,OACAC,KAAK,KACJC,EAAKC,UACT,IAAIpB,IAAOW,EACX,MAAMG,QAAgBhK,KAAKuK,cACvBrB,IAAOW,GACLE,EAAiBD,KAAiBC,EAAiBC,KACrDF,EAAcE,EACdP,EAASO,EAAQQ,SAE7B,EAEMd,UAAUC,aAAac,iBAAiB,eAAgBJ,GACxDA,IACArK,KAAKwH,sBAAwB6C,CACnC,CACI,OAAO,CACX,CAME,uBAAMK,GACJ,MAAMC,QAAyBjB,UAAUkB,YAAYC,MAAM,CACzD9B,KAAM,eAER,GAA+B,WAA3B4B,EAAiBzF,MACnB4F,OAAOC,MAAM,8DACR,GAA+B,WAA3BJ,EAAiBzF,MAC1B,IACE,MAAMK,QAAemE,UAAUC,aAAaqB,aAAa,CACvDtL,OAAO,IAEM6F,EAAO0F,YACfC,SAAStG,GAAUA,EAAMuG,QACjC,CAAC,MAAOvF,GACPkF,OAAOC,MAAM,wDACrB,CAEI,OAAO,CACX,CAME,iBAAMR,GACJ,IACGb,UAAUC,gBACT,qBAAsBD,UAAUC,cAElC,MAAM,IAAI/J,MAAM,wCAEZI,KAAK0K,oBACX,MACMU,SADgB1B,UAAUC,aAAa0B,oBAChBjK,QAC1BkK,GAA2B,eAAhBA,EAAOC,OAEfC,EAAqBJ,EAAaK,WACrCH,GAA+B,YAApBA,EAAOpB,WAEfwB,EAAa,GACnB,IAA4B,IAAxBF,EAA2B,CAC7B,IAAIG,EAAgBP,EAAaQ,OAAOJ,EAAoB,GAAG,GAC3DK,EAAgBT,EAAaK,WAC9BH,GAAWA,EAAOQ,UAAYH,EAAcG,WAExB,IAAnBD,IACFF,EAAgBP,EAAaQ,OAAOC,EAAe,GAAG,IAExDF,EAAcI,SAAU,EACxBL,EAAW1K,KAAK2K,EACtB,CACI,OAAOD,EAAWM,OAAOZ,EAC7B,CAQE,WAAMa,CAAM/B,GACV,GAAIlK,KAAK0H,UACP,MAAM,IAAI9H,MACR,gEAIJ,IACG8J,UAAUC,gBACT,iBAAkBD,UAAUC,cAE9B,MAAM,IAAI/J,MAAM,gCAElB,IACE,MAAMsM,EAAS,CAAExM,OAAO,GACpBwK,IACFgC,EAAOxM,MAAQ,CAAEwK,SAAU,CAAEiC,MAAOjC,KAEtClK,KAAKuF,aAAemE,UAAUC,aAAaqB,aAAakB,EACzD,CAAC,MAAOE,GACP,MAAM,IAAIxM,MAAM,+BACtB,CAEI,MAAM6E,EAAU,IAAIE,aAAa,CAAElF,WAAYO,KAAKP,aAC9CgE,EAASgB,EAAQ4H,wBAAwBrM,KAAKuF,QAEpD,UACQd,EAAQiB,aAAaC,UAAU3F,KAAKsF,UAC3C,CAAC,MAAOM,GAEP,MADAC,QAAQC,MAAMF,GACR,IAAIhG,MAAM,sCAAsCI,KAAKsF,YACjE,CACI,MAAMoC,EAAY,IAAIzB,iBAAiBxB,EAAS,mBAChDiD,EAAUxB,KAAKC,UAAaP,IAC1B,MAAMQ,MAAEA,EAAK8C,GAAEA,EAAEpJ,KAAEA,GAAS8F,EAAE9F,KAC9B,GAAc,YAAVsG,EACFpG,KAAK8H,cAAcoB,GAAMpJ,OACpB,GAAc,UAAVsG,EACT,GAAIpG,KAAKiI,oBAAqB,CAC5B,MAAM/J,EAAS8B,KAAKkI,sBACpBlI,KAAKkI,sBAAwB,CAC3BC,IAAKpK,EAAUe,aAAaZ,EAAOiK,IAAKrI,EAAKqI,KAC7CC,KAAMrK,EAAUe,aAAaZ,EAAOkK,KAAMtI,EAAKsI,OAG/CpI,KAAKkI,sBAAsBE,KAAKjJ,YAChCa,KAAKiI,sBAELjI,KAAKgI,gBAAgBhI,KAAKkI,uBAC1BlI,KAAKkI,sBAAwB,CAC3BC,IAAK,IAAIhK,YAAY,GACrBiK,KAAM,IAAIjK,YAAY,IAGpC,MACU6B,KAAKgI,gBAAgBlI,EAE/B,EAGI,MAAM6H,EAAOlE,EAAOK,QAAQ4D,GACtBjG,EAAWgD,EAAQd,iBAkBzB,OAjBAlC,EAASmC,QAAU,KACnBnC,EAASoC,sBAAwB,GACjC8D,EAAK7D,QAAQrC,GACTzB,KAAKsH,mBAEPzB,QAAQyG,KACN,iJAIF7K,EAASqC,QAAQW,EAAQK,cAG3B9E,KAAKyD,OAASA,EACdzD,KAAK2H,KAAOA,EACZ3H,KAAKyB,SAAWA,EAChBzB,KAAK0H,UAAYA,GACV,CACX,CASE,cAAAlG,CACEG,EAAe,YACfC,GAAc,IACdC,GAAc,IAEd,IAAK7B,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CAElB,OAAO2B,EAAcC,eACnBxB,KAAKyB,SACLzB,KAAKP,WACL,KACAkC,EACAC,EACAC,EAEN,CAOE,WAAM0K,GACJ,IAAKvM,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CACX,IAAKI,KAAK4H,UACf,MAAM,IAAIhI,MAAM,+CAQlB,OANII,KAAKkI,sBAAsBC,IAAIhJ,YACjCa,KAAKgI,gBAAgBhI,KAAKkI,uBAE5BlI,KAAK0I,IAAI,qBACH1I,KAAK8I,OAAO,QAClB9I,KAAK4H,WAAY,GACV,CACX,CAQE,YAAM4E,CAAOC,EAAiB,OAAUC,EAAY,MAClD,IAAK1M,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CACX,GAAII,KAAK4H,UACd,MAAM,IAAIhI,MAAM,iDACX,GAA8B,mBAAnB6M,EAChB,MAAM,IAAI7M,MAAM,qCAWlB,OATAI,KAAKgI,gBAAkByE,EACvBzM,KAAKiI,oBAAsByE,EAC3B1M,KAAKkI,sBAAwB,CAC3BC,IAAK,IAAIhK,YAAY,GACrBiK,KAAM,IAAIjK,YAAY,IAExB6B,KAAK0I,IAAI,uBACH1I,KAAK8I,OAAO,SAClB9I,KAAK4H,WAAY,GACV,CACX,CAME,WAAM+E,GACJ,IAAK3M,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CAGlB,aADMI,KAAK8I,OAAO,UACX,CACX,CAME,UAAM8D,GACJ,IAAK5M,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CAElBI,KAAK0I,IAAI,eAET,aADqB1I,KAAK8I,OAAO,OAErC,CAOE,UAAM+D,CAAKC,GAAQ,GACjB,IAAK9M,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CAElB,IAAKkN,GAAS9M,KAAK4H,UACjB,MAAM,IAAIhI,MACR,iFAGJI,KAAK0I,IAAI,iBACT,MAAMqE,QAAmB/M,KAAK8I,OAAO,UAGrC,OAFe,IAAI/K,GACGyB,KAAKQ,KAAKP,WAAYsN,EAAWrN,MAE3D,CAME,SAAMsN,GACJ,IAAKhN,KAAK0H,UACR,MAAM,IAAI9H,MAAM,6CAGlB,MAAMoJ,EAAahJ,KAAK0H,UAExB1H,KAAK0I,IAAI,sBACH1I,KAAK8I,OAAO,QAClB9I,KAAK4H,WAAY,EACF5H,KAAKuF,OAAO0F,YACpBC,SAAStG,GAAUA,EAAMuG,SAEhCnL,KAAK0I,IAAI,iBACT,MAAMqE,QAAmB/M,KAAK8I,OAAO,SAAU,CAAE,EAAEE,GAEnDhJ,KAAK0H,UAAUrB,aACfrG,KAAKyD,OAAO4C,aACZrG,KAAK2H,KAAKtB,aACVrG,KAAKyB,SAAS4E,aACdrG,KAAKuF,OAAS,KACdvF,KAAK0H,UAAY,KACjB1H,KAAKyD,OAAS,KACdzD,KAAK2H,KAAO,KAIZ,OAFe,IAAI5J,GACGyB,KAAKQ,KAAKP,WAAYsN,EAAWrN,MAE3D,CAOE,UAAMuN,GAKJ,OAJAjN,KAAKwJ,sBAAsB,MACvBxJ,KAAK0H,iBACD1H,KAAKgN,OAEN,CACX,EAGAvM,WAAW4G,YAAcA"}